{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D,UpSampling2D, BatchNormalization, Conv2D,Flatten,Reshape, ZeroPadding2D, Dropout\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.optimizers import RMSprop\n",
    "import os\n",
    "\n",
    "def minmaxrescale(x, a=0, b=1):\n",
    "    \"\"\"\n",
    "    Performs  a MinMax Rescaling on an array `x` to a generic range :math:`[a,b]`.\n",
    "    \"\"\"\n",
    "    xresc = (b - a) * (x - x.min()) / (x.max() - x.min()) + a\n",
    "    return xresc\n",
    "def conv_layer_block(X, f, filters, stage, block, s = 2):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block\n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- integer, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    s -- Integer, specifying the stride to be used\n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    conv_id =   block + str(stage)\n",
    "    X= Dropout(rate=0.3, seed=stage, name='dropout_'+conv_id ) (X)\n",
    "    if s==1:\n",
    "        X = Conv2D( filters  ,  (f,f)  , padding='same',\n",
    "                   kernel_initializer = glorot_uniform(seed=0), name='conv_'+conv_id)(X)\n",
    "    elif s==2:\n",
    "            X = Conv2D( filters  ,  (f,f) , strides=(s,s) , padding='same', name='conv_stride_'+conv_id)(X)\n",
    "\n",
    "    X=Activation('selu' ,  name='seLU_'+conv_id)(X)\n",
    "\n",
    "    X = BatchNormalization(axis=3, name='BN_'+conv_id) (X)\n",
    "\n",
    "    return X\n",
    "\n",
    "def split_trainvaltest_sets(xraw):\n",
    "    nstamps=xraw.shape[0 ]\n",
    "    npix =xraw.shape[1]\n",
    "    nchans=xraw.shape[-1] \n",
    "\n",
    "    ntrains= int (nstamps *  4./5.)\n",
    "    nvals =   int (nstamps * 1./10.)\n",
    "    ntests =    int (nstamps * 1./10.)\n",
    "    return (   xraw[ :ntrains]  ,  xraw[  ntrains:ntrains + nvals] ,  xraw[ -ntests:]  ) \n",
    "\n",
    "class ResUNet:\n",
    "    def __init__(self, output_directory='./', img_size=64,\n",
    "                    epochs=500, batch_size=128, verbose=True,\n",
    "                    pretrained= False ):\n",
    "        self.img_size = img_size\n",
    "        print(f\"Processing  {self.img_size, self.img_size} images\" )\n",
    "        self.nchannels = 2\n",
    "        self.model_directory = output_directory\n",
    "        self.epochs=epochs\n",
    "        self.verbose =verbose\n",
    "        self.batch_size=batch_size\n",
    "        self.pretrained= pretrained\n",
    "\n",
    "    def load_model (self):\n",
    "        json_file = open(self.model_directory+'/models/resunet_model.json', 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        self.model = model_from_json(loaded_model_json)\n",
    "        self.model.compile(loss=\"mean_squared_error\" ,\n",
    "                        optimizer = \"Adam\", metrics=['accuracy'])\n",
    "        # load weights into new model\n",
    "        self.model.load_weights(self.model_directory+\"/models/resunet_model.h5\")\n",
    "        if self.verbose: print(\"Loaded model from disk\")\n",
    "\n",
    "\n",
    "    def preprocess_data(self, arr ):  \n",
    "        if arr.shape[-1]>1: \n",
    "            for i in range(arr.shape[0]): \n",
    "                for k in range(arr.shape[-1]) : \n",
    "                    arr[i,:,:,k]=minmaxrescale(arr[i,:,:,k], a=-1,b=1 ) \n",
    "        else:\n",
    "            for i in range(arr.shape[0]): \n",
    "                arr[i ]=minmaxrescale(arr[i ], a=-1,b=1 ) \n",
    "        xtrain, xval,xtest =split_trainvaltest_sets(arr  )\n",
    "        return xtrain, xval,xtest\n",
    "\n",
    "    def build_resunet(self):\n",
    "        f=5\n",
    "        X_input =  Input(  (self.img_size,self.img_size, self.nchannels ) )\n",
    "        #encoder\n",
    "        X= conv_layer_block(X_input,f, filters=64, stage=1, block='enc_', s=1) #64 x128\n",
    "        Xin=X\n",
    "\n",
    "        X= conv_layer_block(X ,f, filters=64, stage=2, block='enc_', s=1)\n",
    "        X= conv_layer_block(X ,f, filters=64, stage=3, block='enc_', s=1) #skip-conn 1\n",
    "\n",
    "        Xout1=X #64x128 add w/ input of 11-12\n",
    "        X = Add( )([Xin, X ]) #input layer 2  + input layer 4\n",
    "\n",
    "        Xin=X #64x128\n",
    "\n",
    "        X= conv_layer_block(X ,f, filters=128, stage=4, block='enc_', s=2) #128x64\n",
    "        X= conv_layer_block(X ,f, filters=128, stage=5, block='enc_', s=1)\n",
    "\n",
    "        Xin=Conv2D(128  ,  (f,f) , strides=(2,2) , padding='same', name='conv_input_1') (Xin) #128x 64\n",
    "        X = Add( )([Xin, X ]) #input layer 4  + input layer 6\n",
    "        Xin=X\n",
    "\n",
    "        X= conv_layer_block(X ,f, filters=128, stage=6, block='enc_', s=1) #skip-conn 2\n",
    "        Xout2=X  #combine w/ input 8-9\n",
    "\n",
    "        X= conv_layer_block(X ,f, filters=256, stage=7, block='enc_', s=2) #256 x 32\n",
    "        Xin=Conv2D(256  ,  (f,f) , strides=(2,2) , padding='same', name='conv_input_2')(Xin) #256x 32\n",
    "\n",
    "        X=  conv_layer_block(X ,f, filters=128, stage=8, block='dec_', s=1) #128 x32\n",
    "        X = UpSampling2D((2,2),interpolation='nearest', name='upsample_1')(X) #128x 64\n",
    "        #skip-conn2\n",
    "        X = Add( )([Xout2, X ])\n",
    "\n",
    "        Xin=X\n",
    "\n",
    "        X= conv_layer_block(X ,f, filters=128, stage=9, block='dec_', s=1)\n",
    "        X= conv_layer_block(X ,f, filters=128, stage=10, block='dec_', s=1)\n",
    "        X = Add( )([Xin, X ]) #input layer 9  + input layer 11\n",
    "        Xin=X\n",
    "\n",
    "        X= conv_layer_block(X ,f, filters=64, stage=11, block='dec_', s=1) #64x64\n",
    "        X = UpSampling2D((2,2),interpolation='nearest', name='upsample_2' )(X) # 64 x 128\n",
    "\n",
    "        #skip-conn 1\n",
    "        X = Add( )([Xout1, X ])\n",
    "\n",
    "        X= conv_layer_block(X ,f, filters=64, stage=12, block='dec_', s=1)\n",
    "\n",
    "        Xin= Conv2D(64  ,  (f,f) ,   padding='same', name='conv_input_3') (Xin)\n",
    "        Xin = UpSampling2D((2,2),interpolation='nearest', name='upsample_3' )(Xin) # 64 x 128\n",
    "\n",
    "        X = Add( )([Xin, X ]) #input layer 11  + input layer 13\n",
    "        Xin=X\n",
    "        #skip-conn 1\n",
    "        X= conv_layer_block(X ,f, filters=64, stage=13, block='dec_', s=1)\n",
    "        X= conv_layer_block(X ,f, filters=64, stage=14, block='dec_', s=1)\n",
    "        X = Add( )([Xin, X ]) #input layer 13 + input layer 15\n",
    "\n",
    "        Xin= Conv2D(1  ,  (f,f) ,  padding='same', name='conv_input_4') (X )\n",
    "\n",
    "\n",
    "        X= conv_layer_block(X ,f, filters=1, stage=15, block='dec_', s=1) #1x128\n",
    "        X= conv_layer_block(X ,f, filters=1, stage=16, block='dec_', s=1) #1x128\n",
    "        X = Add( )([Xin, X ]) #input layer 15  + last layer\n",
    "\n",
    "        self.model = Model(inputs = X_input, outputs = X, name='ResUNet')\n",
    "        self.model.compile(loss='mean_squared_error',\n",
    "                        optimizer = \"Adam\",\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    def train(self, input_data ,output_data):\n",
    "\n",
    "        if self.pretrained:\n",
    "            self.load_model()\n",
    "        else:\n",
    "            self.build_resunet( )\n",
    "            \n",
    "        x_train,x_val,x_test = self.preprocess_data(input_data)\n",
    "        y_train,y_val,y_test = self.preprocess_data(output_data)\n",
    "\n",
    "        training= self.model.fit(x_train , y_train , epochs=self.epochs ,\n",
    "                                        batch_size=self.batch_size ,\n",
    "                                     shuffle=True, verbose=self.verbose ,\n",
    "                                     validation_data=(x_val ,y_val  ))\n",
    "        scores = self.model.evaluate(x_train, y_train, verbose=self.verbose)\n",
    "        if self.verbose : print( f\"{self.model.metrics_names[1]} :  {scores[1]*100}\" )\n",
    "        save_path = self.model_directory + \"/models\"\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        for key in training.history.keys() :\n",
    "            np.save(save_path + f'/{key}_resunet{self.epochs}.npy', np.array (training.history[key]))\n",
    "        model_json=  self.model.to_json()\n",
    "        with open(save_path+'resunet_model.json', \"w\")  as json_file:\n",
    "            json_file.write(model_json)\n",
    "        self.model.save_weights(save_path+\"resunet_model.h5\")\n",
    "        print(\"saved model to disk\")\n",
    "\n",
    "    def predict(self, Xtest):\n",
    "        return  self.model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dust = np.load('/Users/peppe/work/heavy_maps/Forse_CO_AME/COM_CompMap_Dust-GNILC-F857_2048_R2.00_15amin_training.npz')['patches']\n",
    "nh = np.load('/Users/peppe/work/heavy_maps/Forse_CO_AME/NHI_HI4Pi_16amin_nside2048_inpainted_training.npz')['patches']\n",
    "co = np.load('/Users/peppe/work/heavy_maps/Forse_CO_AME/CO10type2_15amin_nside2048_training.npz')['patches']\n",
    "\n",
    "Xin  = np.stack([dust,nh ], axis=-1)\n",
    "Xout = np.expand_dims(co ,axis=-1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "2\n",
      "1\n",
      "WARNING:tensorflow:From /Users/peppe/miniconda/envs/mlenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1386 samples, validate on 173 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-c4edbde140bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mArch\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mResUNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0moutput_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/Users/peppe/work/extending_CO_AME/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mArch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_resunet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mArch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXin\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0moutput_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXout\u001b[0m   \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-61-4115191cae60>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_data, output_data)\u001b[0m\n\u001b[1;32m    179\u001b[0m                                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                                      \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                                      validation_data=(x_val ,y_val  ))\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34mf\"{self.model.metrics_names[1]} :  {scores[1]*100}\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/mlenv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/miniconda/envs/mlenv/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/mlenv/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/miniconda/envs/mlenv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Arch  = ResUNet(epochs=1,img_size=128,   output_directory='/Users/peppe/work/extending_CO_AME/') \n",
    "Arch.build_resunet() \n",
    "#Arch.model.summary()\n",
    "Arch.train(input_data=Xin , output_data=Xout   )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
